{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font color='lightgrey'>GOAL OF THIS SECTION  \n",
    "    *To compare different approaches for solving the machine learning problem.  \n",
    "    Using different features spaces, different model types, different methods for tuning the models*  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Our project goal phrased as a clear machine learning question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font color='lightgrey'>GOAL OF THIS SECTION  \n",
    "    *To state the intended outcome in machine learning terms.  \n",
    "    To give the features and the target variable we are using.  \n",
    "    To categorize our ML question as a regression or a classification task*  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to predict the cost of a new production order (our target) with a certain accuracy level by using the limited number information available for a new order at project start (our features).\n",
    "\n",
    "The target is the 'cout_unitaire_pour_la_qte_demandee'\n",
    "\n",
    "The features have been described in the preliminary chapter and gathered in the list used_features.\n",
    "Those features correspond to parameters which are typically immediately available within a basic technical folder received at project start.  \n",
    "\n",
    "This is a supervised regression task, as we try to predict a continuous value attribute by training our model with labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) What models are involved and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font color='lightgrey'>GOAL OF THIS SECTION  \n",
    "    *To state which models we plan to use and why (model interpretability, suitability, scalability, diversity, …).  \n",
    "    We use a ranking of our approaches: priority, optional or \"nice to add\"*  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we will compare an average baseline model to the models described inthe sections below.\n",
    "\n",
    "Each time we try to observe our resulting metrics and check if the model is neither underfitting nor overfitting.  \n",
    "To avoid over- or underfitting we will manage the bias/variance trade-off, with tuning model hyperparameters with grid search.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear models\n",
    "A multi-linear regression model with regularisation: ridge model. This will be a simple model to capture linear relationships between features and target.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Linear models\n",
    "Non-linear models to capture non-linear patterns in features:  \n",
    "\n",
    "- Nearest neighbors: we believe it could act well by grouping similar parts, we could also visualize the nearest neighbors (for instance display the corresponding pdf) which is a usefull information for the tender manager, and which would also us to better interpret the results.\n",
    "\n",
    "- Random forest regression: we want to use this robust methodology which performs segmentation of the dataset with if/else rules: the boosting and bagging ensemble methods integrated in the model reduce respectively bias and variance of our decision trees estimators. The benefit of this method is to have a simple model with no hyperparameter having impact on the model complexity, meaning that we do not need to tune the model and we avoid any potential error in the implementation. It will be a good baseline for our non linear models. Random forrest are usually also used for larged datasets as beeing computionaly efficient; in out case with this small dataset, this effect is certainly usefull but not really decisive for the model choice. Also a very informative output from the model will be the possibility to perform classification of the features importance with the .feature_importance_ method. Plotting those will help us to confirm our preliminary assumptions on the importance of the features.\n",
    "\n",
    "- Support vector regression with rbf kernel: should still be effective when dimensionality is greater than cardinality, which might be our case if we use all 3 sources of information we have). With this model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Detailed machine learning strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font color='lightgrey'>*Preprocessing steps of your data for each machine learning model  \n",
    "Methodologies to be used to train and finetune your models  \n",
    "Your baseline model  \n",
    "The metrics and methodologies you are considering to evaluate and compare your models  \n",
    "You should clearly justify any of the above  \n",
    "Feel free to use models that have not been covered in the course. We might ask you to implement a simple version of the model to make sure that you are suitably familiar with this model ahead of starting with the project.*  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting up the notebook with necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', 150)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.simplefilter('ignore',\\\n",
    "         category=(FutureWarning,DeprecationWarning,RuntimeWarning))\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error as MAE,mean_squared_error as MSE\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating variable for path name to the extracted data\n",
    "#devis_path='C:/Users/BS/cpstdata/devis'\n",
    "\n",
    "# Store this variable for usage in other notebooks\n",
    "#%store devis_path\n",
    "\n",
    "# Getting stored data back from original notebooks where data is generated\n",
    "\n",
    "# Clean dataset input to ML after EDA\n",
    "%store -r df_clean_scrome\n",
    "%store -r df_clean_other\n",
    "\n",
    "# original dataset to retrieve information about (for instance about pdf path)\n",
    "%store -r df_merged\n",
    "%store -r quant_features\n",
    "%store -r bool_features\n",
    "%store -r cat_features\n",
    "%store -r cpst_path\n",
    "%store -r git_path\n",
    "\n",
    "#Checking the variables acctive in the notebook\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting-up triggers to control the quantity of notebook outputs\n",
    "\n",
    "profiling_trigger = 1   # Allow profiling reports of the datasets\n",
    "plotting_trigger = 1   # Allow plots of the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features selection\n",
    "\n",
    "We will not integrate feature selection in our ML models and we explain why in the section below:\n",
    "- The EDA does not show outstanding features, rather a sum of many small equivalent contributions. We think that removing some of those could be immediatly detrimental to the ML model predicting capability, in the same proportion as quantity of features removed.  \n",
    "- We currently do ot have a very high dimensionality and we are not at this stage in a logic of improving estimators’ accuracy scores or boost their performance on very high-dimensional datasets.\n",
    "\n",
    "Nevertheless we are curious and we would like to see what the selections algorithm delivers as main features. We will look for the following:  \n",
    "- PCA: will enable us to visualize the contributions of the pricipal components to the variance and confirm the first point above. \n",
    "- T-SNE: alternative non-linear method to see if we have non linear effects.\n",
    "- Selekt KBest: will tell us if the top 5 features impacting target ar the ones we had anticipated in the EDA.  \n",
    "- Random forest: this non-linear model will inform us about feature importance, as described in the model selection section. It will also be a robust baseline model, not impacted by outliers of features transformations.  \n",
    "\n",
    "We will draw conclusions based on those observations, in particular we might conclude that we should extract more of the features types similar to the top5 features (for instance more symbols)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reducing dimensionality to visualize the data projection on 3 principal axes\n",
    "\n",
    "To look at the source 2 and 3, we will be confronted with high-dimensional datasets potentially difficult to visualize.\n",
    "The high-dimensional plots are much less intuitive. We will reduce dimension to allow some degree of visualization of the data structure.\n",
    "\n",
    "Principal Component Analysis (PCA) will be used to choose an “interesting” linear projection of the data that explain a certain % of the variance.\n",
    "We will make a scree plot to show how many PCA components explain 10%, 20%, …, 90% and 100% of the variance.\n",
    "We will then plot the data along the first 3 principal components, with additing additional color or size effects to view supplementary dimensions.\n",
    "We want to observe if the data is spread in linearly separable groups in the defined base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. PCA\n",
    "\n",
    "We first make a scree plot to show how many PCA components explain 10%, 20%, …, 90% and 100% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We setup the libraries for principal component analysis (PCA)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# We also add a standard scaler as well as a pipline object\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the features matrix and the target vector as numpy arrays\n",
    "\n",
    "X=df_clean_scrome.drop(['cout_unitaire_pour_la_qte_demandee'], axis=1)\\\n",
    "            .astype(np.float).values\n",
    "\n",
    "y=df_clean_scrome['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            .astype(np.float).values\n",
    "\n",
    "# We also register the features names in a list for a later usage\n",
    "df_clean_scrome_cols=df_clean_scrome\\\n",
    "            .drop(['cout_unitaire_pour_la_qte_demandee'], axis=1)\\\n",
    "            .columns.to_list()\n",
    "\n",
    "# We register the indexes of our dataframe\n",
    "X_indexes=df_clean_scrome.index.astype(np.int).values\n",
    "\n",
    "print('Shape of features vector X: {}'.format(X.shape))\n",
    "print('Shape of target vector y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA model and fit it to the array of features\n",
    "n_components=X.shape[1]\n",
    "pca=make_pipeline(StandardScaler(),PCA(n_components=n_components))\n",
    "pca.fit(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many component define a specific percentage of the taget variance\n",
    "\n",
    "var_cum=np.cumsum(pca.steps[1][1].explained_variance_ratio_)\n",
    "list_id=[]\n",
    "for thresh in np.arange(0.10,1.0,0.10):\n",
    "    list_id.append([i for i in var_cum if i>thresh][0])\n",
    "for i,j in enumerate(var_cum):\n",
    "    if j in list_id:\n",
    "        print('{} component(s) explain {:.0f} % of the variance'\\\n",
    "                .format(1+i,100*j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the corresponding so called 'Scree plot'\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "first_n=50\n",
    "sns.barplot(np.arange(1,n_components+1)[:first_n],100*pca.steps[1][1]\\\n",
    "            .explained_variance_ratio_[:first_n])\n",
    "plt.step(np.arange(1,n_components+1)[:first_n],\n",
    "         np.cumsum(100*pca.steps[1][1].explained_variance_ratio_[:first_n]))\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Contribution to total variance in %')\n",
    "plt.title('Scree plot - % of variance explained by the first {} components'\\\n",
    "          .format(first_n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to investigate how our datapoints are projected into the base made by the 3 principal components, and visualize it in 3D.   \n",
    "We first need to refit our PCA with n_components=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now setup the plot of the various datapoint inside newly defined PC base\n",
    "\n",
    "# We setup libraries for the 3D visualisations with plotly\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "\n",
    "# We refit the model on 3 components to prepare the base for a display\n",
    "pca.set_params(pca__n_components=3)\n",
    "pca.fit(X);\n",
    "\n",
    "# We project the data onto 3 principal axes\n",
    "X_3d=pca.transform(X)\n",
    "df_X_3d=pd.DataFrame(X_3d).set_index(df_clean_scrome.index)\n",
    "df_X_3d.sort_values(0, ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projects index 961 seem to haver higher than average first principal component.  \n",
    "We will see better in the chart the different groups we may have.   \n",
    "Before we generate the plot, let's analyse how each feature contribute to the 3 principal component defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We group the results in a dataframe and add the percentage of PCA explained\n",
    "# by taking the norm of each vector in the PC base\n",
    "\n",
    "pca0=pca.steps[1][1].components_[0]\n",
    "pca1=pca.steps[1][1].components_[1]\n",
    "pca2=pca.steps[1][1].components_[2]\n",
    "\n",
    "df_results=pd.DataFrame({'variance': X.var(axis=0),\n",
    "                         'pc1':pca.steps[1][1].components_[0],\n",
    "                         'pc2':pca.steps[1][1].components_[1],\n",
    "                         'pc3':pca.steps[1][1].components_[2],\n",
    "                         'PCA_explained':(pca0**2+pca1**2+pca2**2)**(0.5)})\\\n",
    "                    .set_index(df_clean_scrome.drop(\\\n",
    "                        ['cout_unitaire_pour_la_qte_demandee'], axis=1).columns)\n",
    "\n",
    "df_results=df_results.sort_values('PCA_explained', ascending=False)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze each component by inspecting the weights of the loading vectors in the components_ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame by the coefficients of the 1st loading vector\n",
    "\n",
    "df_results.sort_values('pc1', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally plot the target in color in the base made by the 3 first principal components \n",
    "\n",
    "fig = plt.figure(figsize=(18,16))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "vectors=1\n",
    "\n",
    "ax.scatter(X_3d[:,0],\n",
    "           X_3d[:,1],\n",
    "           X_3d[:,2],\n",
    "           zdir='PC 3',\n",
    "           s=40,\n",
    "           alpha=0.8,\n",
    "           marker='o',\n",
    "           c=y)\n",
    "\n",
    "ax.quiver(0,\n",
    "          0,\n",
    "          0,\n",
    "          10*df_results[0:vectors].pc1,\n",
    "          10*df_results[0:vectors].pc2,\n",
    "          10*df_results[0:vectors].pc3,\n",
    "          color = 'red',\n",
    "          alpha = .8,\n",
    "          lw = 1,)#**{'label':1}\n",
    "\n",
    "ax.set_xlabel('Principal component 1')\n",
    "ax.set_ylabel('Principal component 2')\n",
    "ax.set_zlabel('Principal component 3')\n",
    "\n",
    "plt.title('PCA plot - % of variance explained')\n",
    "\n",
    "ax.view_init(elev=25, azim=95)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative interactive plot we show the same results with the plotly library (this requieres the installation of plotlywidget and jupyterlab plotly extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive plot\n",
    "\n",
    "fig = px.scatter_3d(data_frame=df_X_3d,\n",
    "                    x=0,\n",
    "                    y=1,\n",
    "                    z=2,\n",
    "                    opacity=0.8,\n",
    "                    color=y)#size=y[:,0], text=y\n",
    "\n",
    "fig.update_traces(marker=dict(size=5,\n",
    "                     line=dict(width=0,\n",
    "                     color='Black')),\n",
    "                  selector=dict(mode='markers'))\n",
    "\n",
    "#fig.write_html('figure.html', auto_open=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this view we can interactively search for possible clusters of datapoints with similar target values. For instance pc0 negative and high components 1 and 2 correspond to projects 532,534,578.  \n",
    "We can look at those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of projects ids available in the test set\n",
    "# X_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the project technical drawings and informations\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "project_id=578#X_indexes[10]\n",
    "\n",
    "print('Project {}:'.format(project_id))\n",
    "project_id_pdf_path=os.path.normpath(df_merged[df_merged.index==project_id]['pdf_file'].item())\n",
    "if project_id_pdf_path[-2]=='d': \n",
    "    project_id_img_path=project_id_pdf_path[:-4]+'_page1from*.jpg'\n",
    "else:\n",
    "    project_id_img_path=project_id_pdf_path[:-5]+'_page1from*.jpg'\n",
    "#print('{}'.format(project_id_img_path))\n",
    "jn=glob.glob(os.path.normpath(project_id_img_path))[0]\n",
    "print(jn)\n",
    "im=Image.open(jn)\n",
    "size=800,800\n",
    "im.thumbnail(size, Image.ANTIALIAS)\n",
    "display(im)\n",
    "display(pd.DataFrame(X[list(X_indexes).index(project_id),:], index=df_clean_scrome_cols).head(150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed those 3 projects seem to have a similar drawing.  \n",
    "We do not investigate further here for time reasons, but it is interesting to look at points clusters in this kind of chart.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. TSNE\n",
    "\n",
    "To capture potential non linear structures we will also try to use T-SNE, a manifold learning unsupervised algorithm that learns the high-dimensional structure of the data from the data itself, without the use of predetermined classifications.\n",
    "Manifold learning methods are based on a nearest-neighbor search, so we use the Standard Scaler to unsure our results maningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We setup the libraries for non-linear dimensionality reduction method T-SNE\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Build model pipeline including a standard scaler\n",
    "tsne=make_pipeline(StandardScaler(),TSNE(\n",
    "    n_components=3,\n",
    "    perplexity=4.0,\n",
    "    early_exaggeration=12.0,\n",
    "    learning_rate=200.0,\n",
    "    n_iter=5000,\n",
    "    n_iter_without_progress=300,\n",
    "    min_grad_norm=1e-07,\n",
    "    metric='euclidean',\n",
    "    init='random',\n",
    "    verbose=0,\n",
    "    random_state=None,\n",
    "    method='barnes_hut',\n",
    "    angle=0.5))\n",
    "\n",
    "# Fit the model to our arrays of features and generates dataframe\n",
    "# with projection of data onto 3 pricipal axes\n",
    "X_3d=tsne.fit_transform(X)\n",
    "df_X_3d=pd.DataFrame(X_3d)\n",
    "print(df_X_3d.head())\n",
    "\n",
    "# Plot target in the base made by the 3 first principal components \n",
    "fig = px.scatter_3d(data_frame=df_X_3d, x=0, y=1, z=2, opacity=0.8, color=y)\n",
    "#size=y[:,0]\n",
    "fig.update_traces(marker=dict(size=5,\n",
    "                     line=dict(width=0,\n",
    "                     color='Black')),\n",
    "          selector=dict(mode='markers'))\n",
    "#fig.write_html('figure.html', auto_open=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not really see clear clusters of points from this experience with t-distributed Stochastic Neighbor Embedding (t-SNE), and we know this method is very sensitive to parameters tuning, so we drop this part of the analysis for the moment.  \n",
    "\n",
    "If the results is not so clear it's probably because we not no have significant non-linearities in our dataset.  \n",
    "\n",
    "We could reuse this method again when we work with the source 3 (step files) which contains much larger dimension which may be only artificially large.  \n",
    "In this case the use of T-SNE method to find non linear structures in the dataset will make more sense.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reducing dimensionality with selekt k-Best\n",
    "\n",
    "We usually perform feature selection/dimensionality reduction on sample sets to improve estimators’ accuracy scores or to boost their performance on very high-dimensional datasets. In our case we would like to understand which are the best features based on simple univariate statistical tests.\n",
    "We use the SelectKBest class which removes all but the highest scoring features\n",
    "We use the scoring function f_regression as argument in our regression case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection based on SelectKBest\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "\n",
    "# Define number of features to select\n",
    "k=20\n",
    "\n",
    "#Select k best features\n",
    "selector=SelectKBest(f_regression, k=k)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "features_select_id=selector.get_support(indices=True)\n",
    "\n",
    "#Extract the feature names\n",
    "features_select=[df_clean_scrome_cols[i] for i in features_select_id]\n",
    "print('Feature selection based on SelectKBest with k={}'.format(k))\n",
    "features_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the SelektKbest selects the features we already identified as beeing drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / Test split\n",
    "\n",
    "We will perform a train test split just before the model definitions, and keep the test set apart until the end for the scoring of our models on unseen data.  \n",
    "We will use sklearn.model_selection.train_test_split to perform this split.  \n",
    "\n",
    "We estimate that a 25% test set to be kept untouched during the modeling phase is a sufficient value as its corresponds to about 70 samples in the test set (with data cardinality of 280 available to date). We note we are short with overall cardinality, but we assume this is sufficiant for this project which is used as a quick demonstrator.  \n",
    "The risk of this low cardinality in the test set is to have ommitted completely certain categories with low number of representant for instance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning hyperparameters of the models\n",
    "\n",
    "The fine tuning of estimator hyperparameters will be done with exhaustive grid search using **GridSearchCV**, which will search for the best cross validated score.  \n",
    "\n",
    "We will take time to verify that our best hyperparameters are not at the border of the grid parameters range.  \n",
    "\n",
    "List of **estimators and associated parameters** to be gathered in a parameter grid:  \n",
    "We note that only the models 2, 3.1 and 3.3 need tuning for the hyperparameters.  \n",
    "* Model 1: Linear: 0 hypermarameter.\n",
    "* Model 2: Ridge: 1 hyperparameter: alpha (regularization strength).\n",
    "* Model 3.1: kNN: 1 hyperparameter: n_neighbors (number of neighbors), weights (contribution of the local neighborhood='uniform').\n",
    "* Model 3.2: Random Forest: 0 hyperparameter: n_estimator (number of trees in the forest), max_depth (=none), max_features (size of the random subsets of features to consider when splitting a node =none)\n",
    "* Model 3.3: SVR with rbf kernel: 2 hyperparameters: C (trades off misclassification of training examples against simplicity of the decision surface) and Gamma (how much influence a single training example has).  \n",
    "\n",
    "\n",
    "**Cross validation strategy**  \n",
    "* Will be setup with a KFold with a split of 5 to 10. (Or we just assign an interger to the cv argument). \n",
    "* 10 will result in a validation set of 40 for a dataset of 400, which is just reasonable to get a meaningful score.\n",
    "\n",
    "**Score**  \n",
    "We will use a different metrics for the grid search and for the communication of results, in order to be able to interprete the results.   \n",
    "* The metrics coefficient of determination R^2 score is the good default parameter used within the GridSearchCV object to defined the ranking of best scores.  \n",
    "* We will plot the MAE score on the validation curves which is more interpretable for the final comparisons.  \n",
    "\n",
    "**Complexity**  \n",
    "The complexity will not be critical since dataset cardinality & dimensionality are rather small on this project.  \n",
    "Computations will be performed in parallel on the 8 CPU units available on my computer, for the models selected which allow // computation.  \n",
    "Computational cost as a function of model parameters :\n",
    "* Ridge, similar to OLS : O(NFeatures\\*\\*2 \\* NSamples).  \n",
    "* kNN with brute force algorithm: O(NFeatures \\* NSamples\\*\\*2).  \n",
    "* Random Forest: O(NTrees \\* NSamples \\* log(NSamples)) with NTrees number of trees in forest. \n",
    "* SVR with rbf kernel: from O(NFeatures \\* NSamples\\*\\*2) to O(NFeatures \\* NSamples\\*\\*3).  \n",
    "\n",
    "**Best scores / best parameters**  \n",
    "We will display the best parameters and best scores for the models.  \n",
    "Use of DataFrames to present the mean performance on the training and validation folds and the values tested for each hyperparameter.  \n",
    "Sort the results according to the average performance on the validation folds.  \n",
    "\n",
    "**Validation cruves** to visualize over/underfitting  \n",
    "The validation curves correspond to the performance (MAE scores) on the training and validation folds plotted as as a function of the main hyperparameter.(e.g., using the plt.semilogx() function). We will plot the mean from both validation and train sets with tolerance bands centered on the mean and corresponding to the standard deviations). For the different models we will have:  \n",
    "* Ridge: MAE function of alpha.  \n",
    "* kNN: MAE function of neighbors.  \n",
    "* Random Forest: No need for a validation curve, since there is no concept of over or underfitting as such as there is no hyperparameter impacting complexity (we will not tune the tree depth). The over or underfitting is hidden into the bootstrapping.  \n",
    "* SVR: MAE function of C. As many plots as Gamma values. (As alternative we will plot a heatmap, for this will will need to check if we can afford for 10 * 10 computations covering 10 points of gamma and 10 points of C, to have a meaningful display.\n",
    "\n",
    "\n",
    "**Note**  \n",
    "We will probably select one model which seems more promising and refine the tuning on this model only.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communicating the results of the hyperparameters tuning & final comparison (calculated on train & validation sets)\n",
    "\n",
    "\n",
    "MAE will be used since it is easy to interpret in terms of absolute value for our target.\n",
    "\n",
    "- We will compare MAE metrics :\n",
    "  - for each of our 4 models:\n",
    "    - for the best combination of our hyperparameters:\n",
    "      - we will calculate the mean and standard deviation on the (5 to 10) Kfolds.  \n",
    "\n",
    "- We note that this validation curve is performed on points which have been used to tune hyperparameters, which is ok since final model evaluation will be done on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of the model (calculated on unseen test set) \n",
    "\n",
    "\n",
    "- We check that test set is sufficient to peform the analyis: 60 - 80 data points\n",
    "\n",
    "- MAE score is used for each model for comparison purpose\n",
    "\n",
    "- For our best model we will make a scatterplot of the predictions against target:  \n",
    "  - We expect a cloud of points linearly distributed\n",
    "  - We will observe the shape of this cloud and make conclusion on the efficiency of our model for certain values of the target (for instance large or low values)\n",
    "  - We will investigate further the predicted values repartition by adding hue information of some categories of quantitative features, this will help us to see if the model performs +- better in some specific case, and eventually draw conclusion on our features selection/extraction/preprocessing. We already think about the indicator of low quality drawings as a candidate for this test, we will also do it with the top 5 main features selected by our RandomForest most important features.\n",
    "  - We can also check how the errors are correlated to the features with a correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_scrome.drop(['cout_unitaire_pour_la_qte_demandee'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('Shape of features matrix X: {}'.format(X.shape))\n",
    "print('Shape of target vector y: {}'.format(y.shape))\n",
    "\n",
    "# Test train split\n",
    "# Note that in this case we also register the index for a later usage\n",
    "\n",
    "test_size=0.25\n",
    "idx=0\n",
    "X_tr,X_te,y_tr,y_te,X_tr_index,X_te_index=train_test_split(X,y,X_indexes,\n",
    "                                                           test_size=test_size,\n",
    "                                                           random_state=idx)\n",
    "\n",
    "print('Shape train features matrix X_tr:{}'.format(X_tr.shape))\n",
    "print('Shape train target vector y_tr:{}'.format(y_tr.shape))\n",
    "print('Shape test features matrix X_te:{}'.format(X_te.shape))\n",
    "print('Shape test target vector y_te:{}'.format(y_te.shape))\n",
    "print('Shape train features matrix index X_tr_index:{}'\\\n",
    "      .format(X_tr_index.shape))\n",
    "print('Shape test features matrix index X_tr_index:{}'\\\n",
    "      .format(X_te_index.shape))\n",
    "\n",
    "# We mirror this split into original dataframes for later use in this notebook\n",
    "df_clean_scrome_train=df_clean_scrome[df_clean_scrome.index.isin(X_tr_index)].copy()\n",
    "df_clean_scrome_test=df_clean_scrome[df_clean_scrome.index.isin(X_te_index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional addition of test elements from other clients\n",
    "# We create the features matrix and the target vector as numpy arrays\n",
    "\n",
    "X_o=df_clean_other.drop(['cout_unitaire_pour_la_qte_demandee'], axis=1)\\\n",
    "            .astype(np.float).values\n",
    "\n",
    "y_o=df_clean_other['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            .astype(np.float).values\n",
    "\n",
    "# We also register the features names in a list for a later usage\n",
    "df_clean_other_cols=df_clean_other\\\n",
    "            .drop(['cout_unitaire_pour_la_qte_demandee'], axis=1)\\\n",
    "            .columns.to_list()\n",
    "\n",
    "# We register the indexes of our dataframe\n",
    "X_o_index=df_clean_other.index.astype(np.int).values\n",
    "\n",
    "print('Shape of features vector X_o: {}'.format(X_o.shape))\n",
    "print('Shape of target vector y_o: {}'.format(y_o.shape))\n",
    "\n",
    "# We label original dataframes similar to the scrome dataset\n",
    "df_clean_other_test=df_clean_other.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next sections we will perform the modelisation and therefore work only with train set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "We will report the MAE metric computed on the target values in euros (without log scaling) which is easier to interprete.  \n",
    "The coefficient of determinition R^2 is also calculated and reported, we use it since this is a good default parameter in GridSearchCV).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 0 - Baseline\n",
    "\n",
    "We will apply the model on all variables.  \n",
    "We use a dummy regressor with a 'mean' strategy.  \n",
    "We generate prediction and compute the mean absolute error on the complete dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 0 - Baseline\n",
    "# This first model is based on the 'cout_unitaire_pour_la_qte_demandee' mean. \n",
    "\n",
    "# Import the necessary libraries\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error as MAE, r2_score\n",
    "\n",
    "# Create and fit model\n",
    "model_0=DummyRegressor(strategy='mean')\n",
    "model_0.fit(X_tr,y_tr)\n",
    "        \n",
    "# Generate predictions    \n",
    "y_tr_pred=model_0.predict(X_tr)\n",
    "y_te_pred=model_0.predict(X_te)\n",
    "        \n",
    "# Get performance metrics\n",
    "# For the MAE we convert the target back to its original scale\n",
    "MAE_tr_model_0=MAE(10**y_tr,10**y_tr_pred)\n",
    "R2_tr_model_0=r2_score(y_tr,y_tr_pred)\n",
    "MAE_te_model_0=MAE(10**y_te,10**y_te_pred)\n",
    "R2_te_model_0=r2_score(y_te,y_te_pred)\n",
    "\n",
    "#Gather the predictions of the data and print results\n",
    "\n",
    "#TRAIN SET\n",
    "prediction_model_0_train_df=pd.DataFrame()\n",
    "prediction_model_0_train_df['id']=X_tr_index\n",
    "prediction_model_0_train_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_tr_pred, decimals=1)\n",
    "\n",
    "print('Baseline model 0 MAE (train & valid set): {:.1f}'.format(MAE_tr_model_0))\n",
    "print('Baseline model 0 R2 (train & valid set): {:.3f}'.format(R2_tr_model_0))\n",
    "display(prediction_model_0_train_df.head())\n",
    "\n",
    "#TEST SET\n",
    "prediction_model_0_test_df=pd.DataFrame()\n",
    "prediction_model_0_test_df['id']=X_te_index\n",
    "prediction_model_0_test_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_te_pred, decimals=1)\n",
    "\n",
    "print('Baseline model 0 MAE (test set): {:.1f}'.format(MAE_te_model_0))\n",
    "print('Baseline model 0 R2 (test set): {:.3f}'.format(R2_te_model_0))\n",
    "display(prediction_model_0_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are all equal to the target mean in this model as per definition.  \n",
    "Coefficient of determination R2 is zero per definition.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - Linear regression model with 'human' selected variables\n",
    "\n",
    "We will apply the model on 3 variables, which seem to be slightly more correlated with our target from our preliminary EDA: \n",
    "- 'chiffrage_pour_la_qte_demandee_quantite_unite'\n",
    "- '±'\n",
    "- 'quality_indicator_kurtosis'\n",
    "\n",
    "The pipeline will include:\n",
    "- Standard Scaler to help the optimisation algorithm converge.  \n",
    "- Estimator: Linear regression\n",
    "\n",
    "In this first model we use the GridSearchCV object to perform the cross-validation only.  \n",
    "We use it keeping the argument param_grid empty as there are no parameter to tune.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - Linear regression model with 'human' selected variables\n",
    "\n",
    "# We want to select only a few columns corresponding to the features we would like to adress in our features matrix\n",
    "# To do this we set a function to manage correspondance between dataframe columns and np.array corresponding columns indexes\n",
    "def id(L,c):\n",
    "    Li=[]\n",
    "    for i in c:\n",
    "        Li.append(L.index(i))\n",
    "    return Li\n",
    "feature_set_model_1=['chiffrage_pour_la_qte_demandee_quantite_unite','±','quality_indicator_kurtosis']\n",
    "feature_set_model_1_id=id(df_clean_scrome_cols,feature_set_model_1)\n",
    "\n",
    "# Import the necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold #ShuffleSplit\n",
    "\n",
    "# Create model\n",
    "model_1=make_pipeline(StandardScaler(),LinearRegression())\n",
    "\n",
    "# Param grid definition for gridsearch is empty since we have no hyperparameter to tune\n",
    "param_grid_1=[{}]\n",
    "\n",
    "# Cross validation strategy\n",
    "cv_1=KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "#cv=(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "# Grid search\n",
    "gs_1=GridSearchCV(estimator=model_1,\n",
    "                  param_grid=param_grid_1,\n",
    "                  n_jobs=-1,\n",
    "                  refit=True,\n",
    "                  cv=cv_1,\n",
    "                  verbose=1,\n",
    "                  return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit model on the train set\n",
    "gs_1.fit(X_tr[:,feature_set_model_1_id],y_tr)\n",
    "\n",
    "# We display the best parameters for the model\n",
    "# We note there are no hyperparameter in this model\n",
    "print('Best parameters model 1: {}'.format(gs_1.best_params_))\n",
    "\n",
    "# We display the model corresponding best score\n",
    "# We note there are no hyperparameter in this model\n",
    "print('Score model 1 (train & valid set): {:.2f}'.format(gs_1.score(X_tr[:,feature_set_model_1_id],y_tr)))\n",
    "print('Score model 1 (test set): {:.2f}'.format(gs_1.score(X_te[:,feature_set_model_1_id],y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "# We note there are no hyperparameter in this model\n",
    "y_tr_pred=gs_1.predict(X_tr[:,feature_set_model_1_id])\n",
    "y_te_pred=gs_1.predict(X_te[:,feature_set_model_1_id])\n",
    "        \n",
    "# Get performance metrics\n",
    "# For the MAE we convert the target back to its original scale\n",
    "MAE_tr_model_1=MAE(10**y_tr,10**y_tr_pred)\n",
    "R2_tr_model_1=r2_score(y_tr,y_tr_pred)\n",
    "MAE_te_model_1=MAE(10**y_te,10**y_te_pred)\n",
    "R2_te_model_1=r2_score(y_te,y_te_pred)\n",
    "\n",
    "#Gather the predictions of the data and print results\n",
    "\n",
    "#TRAIN SET\n",
    "prediction_model_1_train_df=pd.DataFrame()\n",
    "prediction_model_1_train_df['id']=X_tr_index\n",
    "prediction_model_1_train_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_tr_pred, decimals=1)\n",
    "\n",
    "print('Model 1 MAE (train & valid set): {:.1f}'.format(MAE_tr_model_1))\n",
    "print('Model 1 R2 (train & valid set): {:.3f}'.format(R2_tr_model_1))\n",
    "display(prediction_model_1_train_df.head())\n",
    "\n",
    "#TEST SET\n",
    "prediction_model_1_test_df=pd.DataFrame()\n",
    "prediction_model_1_test_df['id']=X_te_index\n",
    "prediction_model_1_test_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_te_pred, decimals=1)\n",
    "\n",
    "print('Model 1 MAE (test set): {:.1f}'.format(MAE_te_model_1))\n",
    "print('Model 1 R2 (test set): {:.3f}'.format(R2_te_model_1))\n",
    "display(prediction_model_1_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_cols_drop=['mean_fit_time','std_fit_time','mean_score_time','std_score_time',\n",
    "                                    'params','split0_test_score','split1_test_score','split2_test_score',\n",
    "                                    'split3_test_score','split4_test_score','split5_test_score',\n",
    "                                    'split6_test_score','split0_train_score','split1_train_score',\n",
    "                                    'split2_train_score','split3_train_score','split4_train_score',\n",
    "                                    'split5_train_score','split6_train_score']\n",
    "\n",
    "cv_1_results = pd.DataFrame(gs_1.cv_results_).sort_values('rank_test_score')\n",
    "cv_results_cols=cv_1_results.drop(cv_results_cols_drop, axis=1).columns\n",
    "cv_1_results=cv_1_results[cv_results_cols].astype(float).copy()\n",
    "cv_1_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this preliminary simple linear regression model without regularisation, we can predict our target using 3 important features preselected. The model converges towards a solution with a MAE error which is lower than our baseline. This is encouraging. We will now try to incorporate more features. For this we will use a Ridge model with regularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Ridge linear regression model with all variables\n",
    "\n",
    "We will apply the model on the complete features space.  \n",
    "\n",
    "The pipeline will include:  \n",
    "- OPTIONAL depending on results: transforms on the floats extracted from drawings (\\*\\*2, \\*\\*3, log, \\*\\*0.5).  \n",
    "- Addition of polynomial features on the floats extracted from drawings.  \n",
    "- Standard Scaler to help the optimisation algorithm converge and avoid ill-conditionning.  \n",
    "- Estimator: Ridge regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of model 2: linear regression model with ridge estimator\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "# Set up columns transformer to include polynomial features\n",
    "\n",
    "poly_col_id=id(df_clean_scrome_cols,['tolerance_band_mean',\n",
    "                              'tolerance_band_median',\n",
    "                              'tolerance_band_quantile_20',\n",
    "                              'tolerance_band_quantile_80',\n",
    "                              'dimension_band_mean',\n",
    "                              'dimension_band_median',\n",
    "                              'dimension_band_quantile_20',\n",
    "                              'dimension_band_quantile_80'])\n",
    "# Currently not used:\n",
    "#'±','Ra','Ø',\n",
    "#'tolerance_band_count',\n",
    "#'dimension_band_count',\n",
    "#'tolerance_band_min',\n",
    "#'tolerance_band_max',\n",
    "#'tolerance_band_std',     \n",
    "#'tolerance_band_irq',\n",
    "#'dimension_band_min',\n",
    "#'dimension_band_max',\n",
    "#'dimension_band_std',\n",
    "#'dimension_band_irq',\n",
    "#'quality_indicator_kurtosis'\n",
    "# As been tried out and generates overfitting: Score on the train is better but lower on the test set.\n",
    "# Probably we could use those poly features when we have more data points.\n",
    "# When setting the only parameters selected above with degree 2: we get slightly better scores.\n",
    "\n",
    "\n",
    "print('columns for addition of polynomial features:', poly_col_id)\n",
    "poly_transformer = make_pipeline(PolynomialFeatures(degree=2, include_bias=False))\n",
    "transformer = ColumnTransformer([('poly',poly_transformer,poly_col_id)],remainder='passthrough')\n",
    "\n",
    "# Pipeline definition\n",
    "model_2=Pipeline([('transformer',transformer),#None\n",
    "                 ('scaler',StandardScaler()),\n",
    "                 ('estimator',Ridge(alpha=1.0,\n",
    "                                    fit_intercept=True,\n",
    "                                    normalize=False,\n",
    "                                    copy_X=True,\n",
    "                                    max_iter=None,\n",
    "                                    tol=0.001,\n",
    "                                    solver='auto',\n",
    "                                    random_state=0))])\n",
    "\n",
    "# Param grid definition for gridsearch\n",
    "param_grid_2=[{'estimator__alpha':np.logspace(-6,6,num=50)}]\n",
    "\n",
    "# Cross validation strategy\n",
    "cv_2=KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "#cv=(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "# Definition of a custom scorer to be able to score the target values without log scale\n",
    "from sklearn.metrics import make_scorer\n",
    "def mae_func(y,y_pred):\n",
    "    return -np.mean(np.abs(10**y-10**y_pred))\n",
    "custom_scorer=make_scorer(mae_func,greater_is_better=False)\n",
    "\n",
    "\n",
    "# Grid search\n",
    "gs_2=GridSearchCV(estimator=model_2,\n",
    "                  param_grid=param_grid_2,\n",
    "                  scoring={'R2':'r2','MAE':custom_scorer},#None,neg_mean_absolute_error\n",
    "                  n_jobs=-1,\n",
    "                  refit='R2',#True,\n",
    "                  cv=cv_2,\n",
    "                  verbose=1,\n",
    "                  return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit the model on the train set\n",
    "gs_2.fit(X_tr,y_tr)\n",
    "\n",
    "# We display the best parameters for the model\n",
    "print('Best parameters model 2: {}'.format(gs_2.best_params_))\n",
    "\n",
    "# We display the model corresponding best score\n",
    "print('Score model 2 (train & valid set): {:.2f}'.format(gs_2.score(X_tr,y_tr)))\n",
    "print('Score model 2 (test set): {:.2f}'.format(gs_2.score(X_te,y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "# We note the model has been automatically refit on the best parameters\n",
    "y_tr_pred=gs_2.predict(X_tr)\n",
    "y_te_pred=gs_2.predict(X_te)\n",
    "y_o_pred=gs_2.predict(X_o)\n",
    "\n",
    "# Get performance metrics\n",
    "# For the MAE we convert the target back to its original scale\n",
    "MAE_tr_model_2=MAE(10**y_tr,10**y_tr_pred)\n",
    "R2_tr_model_2=r2_score(y_tr,y_tr_pred)\n",
    "MAE_te_model_2=MAE(10**y_te,10**y_te_pred)\n",
    "R2_te_model_2=r2_score(y_te,y_te_pred)\n",
    "\n",
    "MAE_o_model_2=MAE(10**y_o,10**y_o_pred)\n",
    "R2_o_model_2=r2_score(y_o,y_o_pred)\n",
    "\n",
    "#Gather the predictions of the data and print results\n",
    "\n",
    "#TRAIN SET\n",
    "prediction_model_2_train_df=pd.DataFrame()\n",
    "prediction_model_2_train_df['id']=X_tr_index\n",
    "prediction_model_2_train_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_tr_pred, decimals=1)\n",
    "\n",
    "print('Model 2 MAE (train & valid set): {:.1f}'.format(MAE_tr_model_2))\n",
    "print('Model 2 R2 (train & valid set): {:.3f}'.format(R2_tr_model_2))\n",
    "display(prediction_model_2_train_df.head())\n",
    "\n",
    "#TEST SET\n",
    "prediction_model_2_test_df=pd.DataFrame()\n",
    "prediction_model_2_test_df['id']=X_te_index\n",
    "prediction_model_2_test_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_te_pred, decimals=1)\n",
    "\n",
    "print('Model 2 MAE (test set): {:.1f}'.format(MAE_te_model_2))\n",
    "print('Model 2 R2 (test set): {:.3f}'.format(R2_te_model_2))\n",
    "display(prediction_model_2_test_df.head())\n",
    "\n",
    "#TEST SET OTHER\n",
    "prediction_model_2_other_df=pd.DataFrame()\n",
    "prediction_model_2_other_df['id']=X_o_index\n",
    "prediction_model_2_other_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_o_pred, decimals=1)\n",
    "\n",
    "print('Model 2 MAE (other set): {:.1f}'.format(MAE_o_model_2))\n",
    "print('Model 2 R2 (other set): {:.3f}'.format(R2_o_model_2))\n",
    "display(prediction_model_2_other_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the model results and model validation display function\n",
    "\n",
    "# Extract the GridSearchCV results\n",
    "cv_2_results = pd.DataFrame(gs_2.cv_results_)\\\n",
    "                    .drop('params', axis=1)\\\n",
    "                    .astype(float)\\\n",
    "                    .sort_values('param_estimator__alpha')\n",
    "display(cv_2_results.head())\n",
    "\n",
    "# Name the variables to plot \n",
    "alphas=np.log10(cv_2_results['param_estimator__alpha'])\n",
    "\n",
    "rank_te_R2_2=cv_2_results['rank_test_R2']\n",
    "mean_te_R2_2=cv_2_results['mean_test_R2']\n",
    "mean_tr_R2_2=cv_2_results['mean_train_R2']\n",
    "std_te_R2_2=cv_2_results['std_test_R2']\n",
    "std_tr_R2_2=cv_2_results['std_train_R2']\n",
    "\n",
    "rank_te_MAE_2=cv_2_results['rank_test_MAE']\n",
    "mean_te_MAE_2=cv_2_results['mean_test_MAE']\n",
    "mean_tr_MAE_2=cv_2_results['mean_train_MAE']\n",
    "std_te_MAE_2=cv_2_results['std_test_MAE']\n",
    "std_tr_MAE_2=cv_2_results['std_train_MAE']\n",
    "\n",
    "# Identify the GridSearchCV best value\n",
    "idxmin_2=rank_te_R2_2.idxmin()\n",
    "alpha_idxmin_2=alphas[idxmin_2]\n",
    "rank_te_R2_idxmin_2=rank_te_R2_2[idxmin_2]\n",
    "mean_te_R2_idxmin_2=mean_te_R2_2[idxmin_2]\n",
    "std_te_R2_idxmin_2=std_te_R2_2[idxmin_2]\n",
    "rank_te_MAE_idxmin_2=rank_te_MAE_2[idxmin_2]\n",
    "mean_te_MAE_idxmin_2=mean_te_MAE_2[idxmin_2]\n",
    "std_te_MAE_idxmin_2=std_te_MAE_2[idxmin_2]\n",
    "\n",
    "# Store the MAE score for each CV run for final comparison plot\n",
    "S2=cv_2_results.loc[idxmin_2,[c for c in cv_2_results.columns if ('_test_MAE' in c)&('split' in c)]]\n",
    "S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean scores\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(alphas,mean_te_MAE_2, label='validation')\n",
    "plt.plot(alphas,mean_tr_MAE_2, label='train')\n",
    "\n",
    "# Quantify variance of those scores with ±std curves\n",
    "plt.fill_between(alphas,\n",
    "                 mean_te_MAE_2-std_te_MAE_2,\n",
    "                 mean_te_MAE_2+std_te_MAE_2,\n",
    "                 alpha=0.2)\n",
    "plt.fill_between(alphas,\n",
    "                 mean_tr_MAE_2-std_tr_MAE_2,\n",
    "                 mean_tr_MAE_2+std_tr_MAE_2,\n",
    "                 alpha=0.2)\n",
    "\n",
    "# Add marker for best score\n",
    "plt.scatter(alpha_idxmin_2, mean_te_MAE_idxmin_2, marker='o', c='green', zorder=5)\n",
    "\n",
    "# Print best scores\n",
    "plt.title('Best alpha: {:.4f}\\nR2 score: {:.3f} \\u00b1 {:.3f} (rank {:.0f})'\\\n",
    "          .format(10**alpha_idxmin_2,mean_te_R2_idxmin_2,std_te_R2_idxmin_2,rank_te_R2_idxmin_2),\n",
    "          loc='left')\n",
    "plt.annotate('MAE: {:.1f} \\u00b1 {:.1f}'.format(mean_te_MAE_idxmin_2,std_te_MAE_idxmin_2),\n",
    "             xy=(alpha_idxmin_2, mean_te_MAE_idxmin_2),\n",
    "             xytext=(1.8*alpha_idxmin_2, 0.75*mean_te_MAE_idxmin_2),\n",
    "             arrowprops=dict(facecolor='green', shrink=0.05))\n",
    "plt.xlabel('$log_{10}(alpha)$')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(loc=2)\n",
    "plt.grid(color='black', linestyle='--', linewidth=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ridge model is fitted and the hyperparameter alpha optimized to find an optimal MAE score. The MAE error is lower than our model 1. This is encouraging. \n",
    "We will look later in the ML section how the predictions in terms of MAE translates for high or low values of our target.  \n",
    "For the moment the model is not performing well enough to be really usable.  \n",
    "We will now try to incorporate non linearity in the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3.1 - kNN non-linear model with all variables\n",
    "\n",
    "We will apply the model on the complete features space. \n",
    "\n",
    "The pipeline will include:  \n",
    "- Standard Scaler to help the optimisation algorithm converge and avoid ill-conditionning.  \n",
    "- Estimator: kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of model 31: non-linear model with kNN estimator\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Set up columns transformer to include polynomial features\n",
    "# Currently not used\n",
    "poly_col_id=id(df_clean_scrome_cols,[])\n",
    "print('columns for addition of polynomial features:', poly_col_id)\n",
    "poly_transformer = make_pipeline(PolynomialFeatures(degree=3, include_bias=False))\n",
    "transformer = ColumnTransformer([('poly',poly_transformer,poly_col_id)],remainder='passthrough')\n",
    "\n",
    "# Pipeline definition\n",
    "model_31=Pipeline([('transformer',None),#transformer\n",
    "                 ('scaler',StandardScaler()),\n",
    "                 ('estimator',KNeighborsRegressor(n_neighbors=5,\n",
    "                                                  weights='uniform',\n",
    "                                                  algorithm='auto',\n",
    "                                                  leaf_size=30,\n",
    "                                                  p=2,\n",
    "                                                  metric='minkowski',\n",
    "                                                  metric_params=None,\n",
    "                                                  n_jobs=-1))])\n",
    "\n",
    "# Param grid definition for gridsearch\n",
    "param_grid_31=[{'estimator__n_neighbors':[1,2,3,4,5,6,7,8,9,10]}]\n",
    "\n",
    "# Cross validation strategy\n",
    "cv_31=KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "#cv=(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "# Grid search\n",
    "gs_31=GridSearchCV(estimator=model_31,\n",
    "                   param_grid=param_grid_31,\n",
    "                   scoring={'R2':'r2','MAE':custom_scorer},#None\n",
    "                   n_jobs=-1,\n",
    "                   refit='R2',#True,\n",
    "                   cv=cv_31,\n",
    "                   verbose=1,\n",
    "                   return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit the model to the train set\n",
    "gs_31.fit(X_tr,y_tr)\n",
    "\n",
    "# We display the best parameters for the model\n",
    "print('Best parameters model 31: {}'.format(gs_31.best_params_))\n",
    "\n",
    "# We display the model corresponding best score\n",
    "print('Score model 31 (train & valid sets): {:.2f}'.format(gs_31.score(X_tr,y_tr)))\n",
    "print('Score model 31 (test set): {:.2f}'.format(gs_31.score(X_te,y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "# We note the model has been automatically refit on the best parameters\n",
    "y_tr_pred=gs_31.predict(X_tr)\n",
    "y_te_pred=gs_31.predict(X_te)\n",
    "        \n",
    "# Get performance metrics\n",
    "# For the MAE we convert the target back to its original scale\n",
    "MAE_tr_model_31=MAE(10**y_tr,10**y_tr_pred)\n",
    "R2_tr_model_31=r2_score(y_tr,y_tr_pred)\n",
    "MAE_te_model_31=MAE(10**y_te,10**y_te_pred)\n",
    "R2_te_model_31=r2_score(y_te,y_te_pred)\n",
    "\n",
    "#Gather the predictions of the data and print results\n",
    "\n",
    "#TRAIN SET\n",
    "prediction_model_31_train_df=pd.DataFrame()\n",
    "prediction_model_31_train_df['id']=X_tr_index\n",
    "prediction_model_31_train_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_tr_pred, decimals=1)\n",
    "\n",
    "print('Model 31 MAE (train & valid set): {:.1f}'.format(MAE_tr_model_31))\n",
    "print('Model 31 R2 (train & valid set): {:.3f}'.format(R2_tr_model_31))\n",
    "display(prediction_model_31_train_df.head())\n",
    "\n",
    "#TEST SET\n",
    "prediction_model_31_test_df=pd.DataFrame()\n",
    "prediction_model_31_test_df['id']=X_te_index\n",
    "prediction_model_31_test_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_te_pred, decimals=1)\n",
    "\n",
    "print('Model 31 MAE (test set): {:.1f}'.format(MAE_te_model_31))\n",
    "print('Model 31 R2 (test set): {:.3f}'.format(R2_te_model_31))\n",
    "display(prediction_model_31_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the model results and model validation display function\n",
    "\n",
    "# Extract the GridSearchCV results\n",
    "cv_31_results = pd.DataFrame(gs_31.cv_results_)\\\n",
    "                    .drop('params', axis=1)\\\n",
    "                    .astype(float)\\\n",
    "                    .sort_values('param_estimator__n_neighbors')\n",
    "display(cv_31_results.head())\n",
    "\n",
    "# Name the variables to plot \n",
    "nneighs=cv_31_results['param_estimator__n_neighbors']\n",
    "\n",
    "rank_te_R2_31=cv_31_results['rank_test_R2']\n",
    "mean_te_R2_31=cv_31_results['mean_test_R2']\n",
    "mean_tr_R2_31=cv_31_results['mean_train_R2']\n",
    "std_te_R2_31=cv_31_results['std_test_R2']\n",
    "std_tr_R2_31=cv_31_results['std_train_R2']\n",
    "\n",
    "rank_te_MAE_31=cv_31_results['rank_test_MAE']\n",
    "mean_te_MAE_31=cv_31_results['mean_test_MAE']\n",
    "mean_tr_MAE_31=cv_31_results['mean_train_MAE']\n",
    "std_te_MAE_31=cv_31_results['std_test_MAE']\n",
    "std_tr_MAE_31=cv_31_results['std_train_MAE']\n",
    "\n",
    "# Identify the GridSearchCV best value\n",
    "idxmin_31=rank_te_R2_31.idxmin()\n",
    "nneigh_idxmin_31=nneighs[idxmin_31]\n",
    "rank_te_R2_idxmin_31=rank_te_R2_31[idxmin_31]\n",
    "mean_te_R2_idxmin_31=mean_te_R2_31[idxmin_31]\n",
    "std_te_R2_idxmin_31=std_te_R2_31[idxmin_31]\n",
    "rank_te_MAE_idxmin_31=rank_te_MAE_31[idxmin_31]\n",
    "mean_te_MAE_idxmin_31=mean_te_MAE_31[idxmin_31]\n",
    "std_te_MAE_idxmin_31=std_te_MAE_31[idxmin_31]\n",
    "\n",
    "# Store the MAE score for each CV run for final comparison plot\n",
    "S31=cv_31_results.loc[idxmin_31,[c for c in cv_31_results.columns if ('_test_MAE' in c)&('split' in c)]]\n",
    "S31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean scores\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(nneighs,mean_te_MAE_31, label='validation')\n",
    "plt.plot(nneighs,mean_tr_MAE_31, label='train')\n",
    "\n",
    "# Quantify variance of those scores with ±std curves\n",
    "plt.fill_between(nneighs,\n",
    "                 mean_te_MAE_31-std_te_MAE_31,\n",
    "                 mean_te_MAE_31+std_te_MAE_31,\n",
    "                 alpha=0.2)\n",
    "plt.fill_between(nneighs,\n",
    "                 mean_tr_MAE_31-std_tr_MAE_31,\n",
    "                 mean_tr_MAE_31+std_tr_MAE_31,\n",
    "                 alpha=0.2)\n",
    "\n",
    "# Add marker for best score\n",
    "plt.scatter(nneigh_idxmin_31, mean_te_MAE_idxmin_31, marker='o', c='green', zorder=5)\n",
    "\n",
    "# Print best scores\n",
    "plt.title('Best n_neighbors: {:.4f}\\nR2 score: {:.3f} \\u00b1 {:.3f} (rank {:.0f})'\\\n",
    "          .format(nneigh_idxmin_31,mean_te_R2_idxmin_31,std_te_R2_idxmin_31,rank_te_R2_idxmin_31),\n",
    "          loc='left')\n",
    "plt.annotate('MAE: {:.1f} \\u00b1 {:.1f}'.format(mean_te_MAE_idxmin_31,std_te_MAE_idxmin_31),\n",
    "             xy=(nneigh_idxmin_31, mean_te_MAE_idxmin_31),\n",
    "             xytext=(1.8*nneigh_idxmin_31, 0.75*mean_te_MAE_idxmin_31),\n",
    "             arrowprops=dict(facecolor='green', shrink=0.05))\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(loc=2)\n",
    "plt.grid(color='black', linestyle='--', linewidth=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kNN model is fitted and the hyperparameter n_neighbors optimized to find an optimal MAE score. The MAE error is lower than our model 2. This is encouraging. We nevertheless get a MAE score which is not sufficient for our application. \n",
    "\n",
    "One usefull characteristic is that we can try to visualize the nearest neigbors of one project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of projects ids available in the test set\n",
    "X_te_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a fonction to extract the first neighbors of a project in the test set, and a one to plot them\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Function to find the neighbors of a project by project from its id\n",
    "\n",
    "def neighbors(proj_id):\n",
    "    N=gs_31.best_estimator_\\\n",
    "                .steps[2][1]\\\n",
    "                .kneighbors(X=X_te[list(X_te_index)\\\n",
    "                                   .index(proj_id),:]\\\n",
    "                            .reshape((1,-1)),\n",
    "                            n_neighbors=n_nearest,\n",
    "                            return_distance=True)\n",
    "    \n",
    "    return list(N[1][0]), list(N[0][0])\n",
    "\n",
    "n_nearest=3\n",
    "\n",
    "project_id=X_te_index[10]\n",
    "\n",
    "print('The first {} neighbors of the project id {} are: {}\\n'\\\n",
    "      .format(n_nearest,\n",
    "              project_id,\n",
    "              neighbors(project_id)[0]))\n",
    "\n",
    "# Function to display the project and corresponding neighbors technical\n",
    "# drawings and informations\n",
    "\n",
    "# Display project drawing and informations\n",
    "\n",
    "print('Project {}:'.format(project_id))\n",
    "project_id_pdf_path=os.path.normpath(df_merged[df_merged.index==project_id]['pdf_file'].item())\n",
    "if project_id_pdf_path[-2]=='d': \n",
    "    project_id_img_path=project_id_pdf_path[:-4]+'_page1from*.jpg'\n",
    "else:\n",
    "    project_id_img_path=project_id_pdf_path[:-5]+'_page1from*.jpg'\n",
    "#print('{}'.format(project_id_img_path))\n",
    "jn=glob.glob(os.path.normpath(project_id_img_path))[0]\n",
    "print(jn)\n",
    "im=Image.open(jn)\n",
    "size=400,400\n",
    "im.thumbnail(size, Image.ANTIALIAS)\n",
    "display(im)\n",
    "display(pd.DataFrame(X_te[list(X_te_index).index(project_id),:], index=df_clean_scrome_cols))\n",
    "\n",
    "# Display neighbors drawings and informations\n",
    "\n",
    "print('\\n{} nearest neighbors:'.format(n_nearest))\n",
    "list_pdf=list(df_merged[df_merged.index.isin(neighbors(project_id)[0])]['pdf_file'])\n",
    "list_images=[i[:-4]+'_page1from*.jpg' if i[-2]=='d' else i[:-5]+'_page1from*.jpg' for i in list_pdf]\n",
    "for i in list_images:\n",
    "    #print('{}'.format(os.path.normpath(i)))\n",
    "    jn=glob.glob(os.path.normpath(i))[0]\n",
    "    print(jn)\n",
    "    im=Image.open(jn)\n",
    "    size=400,400\n",
    "    im.thumbnail(size, Image.ANTIALIAS)\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exemple we see that the 3 neighbors include 2 times the same drawing; this is because th drawing is not the only parameter in our features space, and we can have several project with same drawing and different quantities for instance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3.2 - Random Forest non-linear model with all variables\n",
    "\n",
    "We will apply the model on the complete features space. \n",
    "\n",
    "The pipeline will include:   \n",
    "- No scaler, no feature engineering.  \n",
    "- Estimator: Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of model 32: non-linear model with Random Forest estimator\n",
    "\n",
    "# Import the necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create and fit model\n",
    "model_32=RandomForestRegressor(n_estimators=1000,\n",
    "                               criterion='mse',\n",
    "                               max_depth=None,\n",
    "                               min_samples_split=2,\n",
    "                               min_samples_leaf=1,\n",
    "                               min_weight_fraction_leaf=0.0,\n",
    "                               max_features='auto',\n",
    "                               max_leaf_nodes=None,\n",
    "                               min_impurity_decrease=0.0,\n",
    "                               min_impurity_split=None,\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=0,\n",
    "                               verbose=1,\n",
    "                               warm_start=False,\n",
    "                               ccp_alpha=0.0,\n",
    "                               max_samples=None)\n",
    "\n",
    "# We fit the model on the train set\n",
    "model_32.fit(X_tr,y_tr)\n",
    "        \n",
    "# Generate predictions    \n",
    "y_tr_pred=model_32.predict(X_tr)\n",
    "y_te_pred=model_32.predict(X_te)\n",
    "        \n",
    "# Get performance metrics\n",
    "# For the MAE we convert the target back to its original scale\n",
    "MAE_tr_model_32=MAE(10**y_tr,10**y_tr_pred)\n",
    "R2_tr_model_32=r2_score(y_tr,y_tr_pred)\n",
    "MAE_te_model_32=MAE(10**y_te,10**y_te_pred)\n",
    "R2_te_model_32=r2_score(y_te,y_te_pred)\n",
    "\n",
    "#Gather the predictions of the data and print results\n",
    "\n",
    "#TRAIN SET\n",
    "prediction_model_32_train_df=pd.DataFrame()\n",
    "prediction_model_32_train_df['id']=X_tr_index\n",
    "prediction_model_32_train_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_tr_pred, decimals=1)\n",
    "\n",
    "print('Model 32 MAE (train & valid set): {:.1f}'.format(MAE_tr_model_32))\n",
    "print('Model 32 R2 (train & valid set): {:.3f}'.format(R2_tr_model_32))\n",
    "display(prediction_model_32_train_df.head())\n",
    "\n",
    "#TEST SET\n",
    "prediction_model_32_test_df=pd.DataFrame()\n",
    "prediction_model_32_test_df['id']=X_te_index\n",
    "prediction_model_32_test_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_te_pred, decimals=1)\n",
    "\n",
    "print('Model 32 MAE (test set): {:.1f}'.format(MAE_te_model_32))\n",
    "print('Model 32 R2 (test set): {:.3f}'.format(R2_te_model_32))\n",
    "display(prediction_model_32_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the feature importance\n",
    "# (Code adapted from the sklearn library exemple)\n",
    "\n",
    "importances = model_32.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in model_32.estimators_],axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "n_first=20\n",
    "print('Feature ranking ({} first):'.format(n_first))\n",
    "\n",
    "feature_names=[]\n",
    "for f in range(X.shape[1])[:n_first]:\n",
    "    print('{:>6}. feature {:>3} ({:.6f}) : {}'.format(f + 1, indices[f], importances[indices[f]],df_clean_scrome_cols[indices[f]]))\n",
    "    feature_names.append(df_clean_scrome_cols[indices[f]])\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.title('Feature importances (first {}): impurity-based feature importances of the forest, along with their inter-trees variability'.format(n_first))\n",
    "ax.barh(range(X.shape[1])[:n_first], importances[indices][:n_first],\n",
    "        color='r', xerr=std[indices][:n_first], align='center')\n",
    "plt.yticks(range(X.shape[1])[:n_first], feature_names,rotation=0)\n",
    "#plt.xlim([-1, X.shape[1]])\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest appear to be our best model in terms of MAE score.  \n",
    "We are also interested in the ranking of features importance as we have announced before.  \n",
    "This is here extremely interesting as it confirms our previous findings about the importance of features, in particular it shows that the ± extracted parameter is part of the main drivers. It tells us that we should try to extract more of those from our drawings, similar ones, which should help our model to give better results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3.3 - SVR non-linear model with all variables\n",
    "\n",
    "We will apply the model on the complete features space. \n",
    "\n",
    "The pipeline will include:  \n",
    "\n",
    "- No feature enginnering (to be checked).\n",
    "- Standard Scaler to help the optimisation algorithm converge and avoid ill-conditionning.  \n",
    "- Estimator: SVR with rbf kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of model 33: non-linear model with SVR estimator\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Set up columns transformer to include polynomial features\n",
    "# Currently not used\n",
    "poly_col_id=id(df_clean_scrome_cols,[])\n",
    "print('columns for addition of polynomial features:', poly_col_id)\n",
    "poly_transformer = make_pipeline(PolynomialFeatures(degree=3, include_bias=False))\n",
    "transformer = ColumnTransformer([('poly',poly_transformer,poly_col_id)],remainder='passthrough')\n",
    "\n",
    "# Pipeline definition\n",
    "model_33=Pipeline([('transformer',None),#transformer\n",
    "                 ('scaler',StandardScaler()),\n",
    "                 ('estimator',SVR(kernel='rbf',\n",
    "                                  gamma='scale',\n",
    "                                  tol=0.001,\n",
    "                                  C=1.0,\n",
    "                                  epsilon=0.1,\n",
    "                                  shrinking=True,\n",
    "                                  cache_size=200,\n",
    "                                  verbose=True,\n",
    "                                  max_iter=-1,))])\n",
    "\n",
    "# Param grid definition for gridsearch\n",
    "param_grid_33=[{'estimator__C':np.logspace(-4,7,num=55),\n",
    "                'estimator__epsilon':np.logspace(-6,0,num=25)}]\n",
    "\n",
    "# Cross validation strategy\n",
    "cv_33=KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "#cv=(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "# Grid search\n",
    "gs_33=GridSearchCV(estimator=model_33,\n",
    "                   param_grid=param_grid_33,\n",
    "                   scoring={'R2':'r2','MAE':custom_scorer},#custom_scorer,\n",
    "                   n_jobs=-1,\n",
    "                   refit='R2',#True,\n",
    "                   cv=cv_33,\n",
    "                   verbose=1,\n",
    "                   return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit the model to the train set\n",
    "gs_33.fit(X_tr,y_tr)\n",
    "\n",
    "# We display the best parameters for the model\n",
    "print('Best parameters model 33: {}'.format(gs_33.best_params_))\n",
    "\n",
    "# We display the model corresponding best score\n",
    "print('Score model 33 (train & valid set): {:.2f}'.format(gs_33.score(X_tr,y_tr)))\n",
    "print('Score model 33 (test set): {:.2f}'.format(gs_33.score(X_te,y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "# We note the model has been automatically refit on the best parameters\n",
    "y_tr_pred=gs_33.predict(X_tr)\n",
    "y_te_pred=gs_33.predict(X_te)\n",
    "        \n",
    "# Get performance metrics\n",
    "# For the MAE we convert the target back to its original scale\n",
    "MAE_tr_model_33=MAE(10**y_tr,10**y_tr_pred)\n",
    "R2_tr_model_33=r2_score(y_tr,y_tr_pred)\n",
    "MAE_te_model_33=MAE(10**y_te,10**y_te_pred)\n",
    "R2_te_model_33=r2_score(y_te,y_te_pred)\n",
    "\n",
    "#Gather the predictions of the data and print results\n",
    "\n",
    "#TRAIN SET\n",
    "prediction_model_33_train_df=pd.DataFrame()\n",
    "prediction_model_33_train_df['id']=X_tr_index\n",
    "prediction_model_33_train_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_tr_pred, decimals=1)\n",
    "\n",
    "print('Model 33 MAE (train & valid set): {:.1f}'.format(MAE_tr_model_33))\n",
    "print('Model 33 R2 (train & valid set): {:.3f}'.format(R2_tr_model_33))\n",
    "display(prediction_model_33_train_df.head())\n",
    "\n",
    "#TEST SET\n",
    "prediction_model_33_test_df=pd.DataFrame()\n",
    "prediction_model_33_test_df['id']=X_te_index\n",
    "prediction_model_33_test_df['cout_unitaire_pour_la_qte_demandee']=np.round(10**y_te_pred, decimals=1)\n",
    "\n",
    "print('Model 33 MAE (test set): {:.1f}'.format(MAE_te_model_33))\n",
    "print('Model 33 R2 (test set): {:.3f}'.format(R2_te_model_33))\n",
    "display(prediction_model_33_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the model results and model validation display function\n",
    "\n",
    "# Extract the GridSearchCV results\n",
    "cv_33_results = pd.DataFrame(gs_33.cv_results_)\\\n",
    "                    .drop('params', axis=1)\\\n",
    "                    .astype(float)\\\n",
    "                    .sort_values('param_estimator__C')\n",
    "\n",
    "for epsilon in cv_33_results['param_estimator__epsilon'].sort_values().unique().tolist():\n",
    "\n",
    "    # Filter the data frame by epsilon\n",
    "    cv_33_results_epsilon=cv_33_results[cv_33_results['param_estimator__epsilon']==epsilon]\\\n",
    "                            .sort_values('param_estimator__C').copy()\n",
    "    \n",
    "    display(cv_33_results_epsilon.head())\n",
    "    \n",
    "    # Name the variables to plot \n",
    "    cs=np.log10(cv_33_results_epsilon['param_estimator__C'])\n",
    "\n",
    "    rank_te_R2_33=cv_33_results_epsilon['rank_test_R2']\n",
    "    mean_te_R2_33=cv_33_results_epsilon['mean_test_R2']\n",
    "    mean_tr_R2_33=cv_33_results_epsilon['mean_train_R2']\n",
    "    std_te_R2_33=cv_33_results_epsilon['std_test_R2']\n",
    "    std_tr_R2_33=cv_33_results_epsilon['std_train_R2']\n",
    "\n",
    "    rank_te_MAE_33=cv_33_results_epsilon['rank_test_MAE']\n",
    "    mean_te_MAE_33=cv_33_results_epsilon['mean_test_MAE']\n",
    "    mean_tr_MAE_33=cv_33_results_epsilon['mean_train_MAE']\n",
    "    std_te_MAE_33=cv_33_results_epsilon['std_test_MAE']\n",
    "    std_tr_MAE_33=cv_33_results_epsilon['std_train_MAE']\n",
    "\n",
    "    # Identify the optimal value\n",
    "    idxmin_33=rank_te_R2_33.idxmin()\n",
    "    c_idxmin_33=cs[idxmin_33]\n",
    "    rank_te_R2_idxmin_33=rank_te_R2_33[idxmin_33]\n",
    "    mean_te_R2_idxmin_33=mean_te_R2_33[idxmin_33]\n",
    "    std_te_R2_idxmin_33=std_te_R2_33[idxmin_33]\n",
    "    rank_te_MAE_idxmin_33=rank_te_MAE_33[idxmin_33]\n",
    "    mean_te_MAE_idxmin_33=mean_te_MAE_33[idxmin_33]\n",
    "    std_te_MAE_idxmin_33=std_te_MAE_33[idxmin_33]\n",
    "\n",
    "    # Store rank 1 value for end comparison\n",
    "    if rank_te_R2_idxmin_33 == 1:\n",
    "        mean_te_MAE_idxmin_33_rank1=mean_te_MAE_idxmin_33\n",
    "        std_te_MAE_idxmin_33_rank1=std_te_MAE_idxmin_33\n",
    "        \n",
    "        # Store the MAE score for each CV run for final comparison plot\n",
    "        S33=cv_33_results.loc[idxmin_33,[c for c in cv_33_results.columns if ('_test_MAE' in c)&('split' in c)]]\n",
    "        print(S33)\n",
    "    \n",
    "    # Plot mean scores\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(cs,mean_te_MAE_33, label='validation')\n",
    "    plt.plot(cs,mean_tr_MAE_33, label='train')\n",
    "\n",
    "    # Quantify variance of those scores with ±std curves\n",
    "    plt.fill_between(cs,\n",
    "                     mean_te_MAE_33-std_te_MAE_33,\n",
    "                     mean_te_MAE_33+std_te_MAE_33,\n",
    "                     alpha=0.2)\n",
    "    plt.fill_between(cs,\n",
    "                     mean_tr_MAE_33-std_tr_MAE_33,\n",
    "                     mean_tr_MAE_33+std_tr_MAE_33,\n",
    "                     alpha=0.2)\n",
    "\n",
    "    # Add marker for best score\n",
    "    plt.scatter(c_idxmin_33, mean_te_MAE_idxmin_33, marker='o', c='green', zorder=5)\n",
    "\n",
    "    # Print best scores\n",
    "    plt.title('Hyperparameter epsilon: {}\\nHyperparameter C best: {:.4f}\\nR2 score: {:.3f} \\u00b1 {:.3f} (rank {:.0f})'\\\n",
    "              .format(epsilon,10**c_idxmin_33,mean_te_R2_idxmin_33,std_te_R2_idxmin_33,rank_te_R2_idxmin_33),\n",
    "              loc='left')\n",
    "    plt.annotate('MAE: {:.2f} \\u00b1 {:.2f}'.format(mean_te_MAE_idxmin_33,std_te_MAE_idxmin_33),\n",
    "                 xy=(c_idxmin_33, mean_te_MAE_idxmin_33),\n",
    "                 xytext=(5*c_idxmin_33, 1.8*mean_te_MAE_idxmin_33),\n",
    "                 arrowprops=dict(facecolor='green', shrink=0.05))\n",
    "    plt.xlabel('$log_{10}(C)$')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(color='black', linestyle='--', linewidth=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the validation curve in 2D on a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataframe to display the 2D view of GridSearch Validation\n",
    "pivot_df=cv_33_results[['param_estimator__C','param_estimator__epsilon','mean_test_MAE']].astype(float).copy()\n",
    "#pd.options.display.float_format = '${:,.2f}'.format\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_map=pivot_df.pivot(index='param_estimator__C', columns='param_estimator__epsilon', values='mean_test_MAE')\n",
    "pivot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the heatmap of MAE scores on test test along the 2 hyperparameters dimensions\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(8, 6))\n",
    "heatmap=sns.heatmap(pivot_map,\n",
    "                    vmin=pivot_map.min().min(), vmax=pivot_map.max().max(),\n",
    "                    annot=False,\n",
    "                    cmap='Blues')#,\n",
    "                    #cbar_kws=dict(orientation='vertical')\n",
    "heatmap.set_title('heatmap of MAE scores on validation set along the 2 hyperparameters dimensions',\n",
    "                  fontdict={'fontsize':12}, pad=12)\n",
    "plt.tick_params(axis='x', which='both',\n",
    "                labelbottom = True,top=False, labeltop=False, labelrotation=90)\n",
    "\n",
    "ax.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n",
    "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores on the TRAIN & VALID set: \\n')\n",
    "print('MAE  model 0     Baseline mean {:>26.1f} EUR'.format(MAE_tr_model_0))\n",
    "print('MAE  model 1     Linear Regression 3 features {:>11.1f} EUR'.format(MAE_tr_model_1))\n",
    "print('MAE  model 2     Ridge {:>29.1f} \\u00b1{:.1f} EUR'.format(mean_te_MAE_idxmin_2,std_te_MAE_idxmin_2))\n",
    "print('MAE  model 3.1   kNN {:>31.1f} \\u00b1{:.1f} EUR'.format(mean_te_MAE_idxmin_31,std_te_MAE_idxmin_31))\n",
    "print('MAE  model 3.2   RandomForest {:>27.1f} EUR'.format(MAE_tr_model_32,1))\n",
    "print('MAE  model 3.3   SVR {:>31.1f} \\u00b1{:.1f} EUR'.format(mean_te_MAE_idxmin_33_rank1,std_te_MAE_idxmin_33_rank1))\n",
    "\n",
    "print('\\nScores on the TEST set: \\n')\n",
    "print('MAE  model 0     Baseline mean {:>26.1f} EUR'.format(MAE_te_model_0))\n",
    "print('MAE  model 1     Linear Regression 3 features {:>11.1f} EUR'.format(MAE_te_model_1))\n",
    "print('MAE  model 2     Ridge {:>34.1f} EUR'.format(MAE_te_model_2))\n",
    "print('MAE  model 3.1   kNN {:>36.1f} EUR'.format(MAE_te_model_31))\n",
    "print('MAE  model 3.2   RandomForest {:>27.1f} EUR'.format(MAE_te_model_32))\n",
    "print('MAE  model 3.3   SVR {:>36.1f} EUR'.format(MAE_te_model_33))\n",
    "\n",
    "print('\\nScores on the OTHER TEST set: \\n')\n",
    "print('MAE  model 2     Ridge {:>34.1f} EUR'.format(MAE_o_model_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# Gathering and plotting results on the train&validation set\n",
    "\n",
    "S0=pd.Series(np.full_like(S2,MAE_tr_model_0))\n",
    "S1=pd.Series(np.full_like(S2,MAE_tr_model_1))\n",
    "S32=pd.Series(np.full_like(S2,MAE_tr_model_32))\n",
    "\n",
    "models_df_tr=pd.concat([S0,S1,S2,S31,S32,S33],\n",
    "                       axis=0,\n",
    "                       keys=['Baseline (mean)','model 1 (Lr)',\n",
    "                             'model 2 (Ridge)','model 3.1 (kNN)',\n",
    "                             'model 3.2 (RF)','model 3.3 (SVR)'])\n",
    "\n",
    "models_df_tr=models_df_tr.reset_index()\n",
    "\n",
    "models_df_tr.columns=['Model','Run','MAE']\n",
    "\n",
    "sns.boxplot(x='Model',y='MAE',data=models_df_tr, linewidth=0.5, palette='Set2')\n",
    "\n",
    "sns.swarmplot(x='Model',y='MAE',data=models_df_tr)\n",
    "\n",
    "# Gathering results and plotting on the test set\n",
    "\n",
    "S0_te=pd.Series(MAE_te_model_0)\n",
    "S1_te=pd.Series(MAE_te_model_1)\n",
    "S2_te=pd.Series(MAE_te_model_2)\n",
    "S31_te=pd.Series(MAE_te_model_31)\n",
    "S32_te=pd.Series(MAE_te_model_32)\n",
    "S33_te=pd.Series(MAE_te_model_33)\n",
    "\n",
    "models_df_te=pd.concat([S0_te,S1_te,S2_te,S31_te,S32_te,S33_te],\n",
    "                       axis=0,\n",
    "                       keys=['Baseline (mean)','model 1 (Lr)',\n",
    "                             'model 2 (Ridge)','model 3.1 (kNN)',\n",
    "                             'model 3.2 (RF)','model 3.3 (SVR)'])\n",
    "\n",
    "models_df_te=models_df_te.reset_index()\n",
    "\n",
    "models_df_te.columns=['Model','Run','MAE']\n",
    "\n",
    "sns.swarmplot(x='Model',y='MAE',data=models_df_te, color='red',\n",
    "              marker='*',size=20, edgecolor='black', linewidth=1)\n",
    "\n",
    "plt.grid()\n",
    "plt.ylabel('MAE in EUR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart gives an overview of the model performance, and it seems that the RF and the Ridge perform better.  \n",
    "This is what we see when we play with the level of outliers detection.  \n",
    "With the dataset we have now we manage to get test set prediction with Ridge at about MAE=10 at a minimum, and Ridge and RF are always close on the test set.\n",
    "\n",
    "We now want to understand how the model predicts low or higher values of the target, and to see where the model perform: We want to understand which categories are better predicted. This is what we do in the next chapter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check predictions\n",
    "\n",
    "We feedback the data in the original dataframe and compare the prediction to the original true data.  \n",
    "\n",
    "Again we generate a collection of plotting functions designed for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column with index for merging purpose\n",
    "\n",
    "df_clean_scrome_train['id']=df_clean_scrome_train.index\n",
    "df_clean_scrome_test['id']=df_clean_scrome_test.index\n",
    "df_clean_other_test['id']=df_clean_other_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predictions with original dataframes\n",
    "\n",
    "df_clean_scrome_train=df_clean_scrome_train.merge(prediction_model_1_train_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred1'))\\\n",
    "                            .set_index('id',verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_scrome_train=df_clean_scrome_train.merge(prediction_model_2_train_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred2'))\\\n",
    "                            .set_index('id',verify_integrity=True)\n",
    "\n",
    "df_clean_scrome_train=df_clean_scrome_train.merge(prediction_model_31_train_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred31'))\\\n",
    "                            .set_index('id',verify_integrity=True)\n",
    "\n",
    "df_clean_scrome_train=df_clean_scrome_train.merge(prediction_model_32_train_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred32'))\\\n",
    "                            .set_index('id',verify_integrity=True)\n",
    "\n",
    "df_clean_scrome_train=df_clean_scrome_train.merge(prediction_model_33_train_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred33'))\\\n",
    "                            .set_index('id',verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_scrome_test=df_clean_scrome_test.merge(prediction_model_1_test_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred1'))\\\n",
    "                            .set_index('id',verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_scrome_test=df_clean_scrome_test.merge(prediction_model_2_test_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred2'))\\\n",
    "                            .set_index('id',verify_integrity=True)\n",
    "\n",
    "df_clean_scrome_test=df_clean_scrome_test.merge(prediction_model_31_test_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred31'))\\\n",
    "                            .set_index('id',verify_integrity=True)\n",
    "\n",
    "df_clean_scrome_test=df_clean_scrome_test.merge(prediction_model_32_test_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred32'))\\\n",
    "                            .set_index('id',verify_integrity=True)\n",
    "\n",
    "df_clean_scrome_test=df_clean_scrome_test.merge(prediction_model_33_test_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred33'))\\\n",
    "                            .set_index('id',verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_other_test=df_clean_other_test.merge(prediction_model_2_other_df,\n",
    "                                how='left',on='id',suffixes=('', '_pred2'))\\\n",
    "                            .set_index('id',verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_scrome_train.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_scrome_test.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_other_test.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first plot the absolute values in Eur of the predictions in relation to the true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scat_only_assy(cols):\n",
    "    \n",
    "    for c in cols:\n",
    "        fig, ax = plt.subplots(2,3, figsize=(16,10), sharey=True)\n",
    "        \n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred1'],\n",
    "                        ax=ax[0,0], alpha=0.4)        \n",
    "        ax[0,0].set_title('MODEL 1 - lr - Test data')\n",
    "\n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred2'],\n",
    "                        ax=ax[0,1], alpha=0.4)\n",
    "        ax[0,1].set_title('MODEL 2 - Ridge - Test data')  \n",
    "        \n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred31'],\n",
    "                        ax=ax[1,0], alpha=0.4)\n",
    "        ax[1,0].set_title('MODEL 3.1 - kNN - Test data')    \n",
    "\n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred32'],\n",
    "                        ax=ax[1,1], alpha=0.4)\n",
    "        ax[1,1].set_title('MODEL 3.2 - RF - Test data')  \n",
    "\n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred33'],\n",
    "                        ax=ax[1,2], alpha=0.4)\n",
    "        ax[1,2].set_title('MODEL 3.3 - SVR - Test data')  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting_trigger==1:\n",
    "    \n",
    "    check_scat_only_assy(['cout_unitaire_pour_la_qte_demandee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are then interested to plot the relative error of the predictions in relation to the true value.  \n",
    "Those relative percentage errors are still massive but the system is in place are ready to include any improvement.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scat_only_assy_ratio(cols):\n",
    "    \n",
    "    for c in cols:\n",
    "        fig, ax = plt.subplots(2,3, figsize=(16,10), sharey=True)\n",
    "        \n",
    "        ratio_pred1=(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "                         -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred1'])\\\n",
    "                            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c], y=ratio_pred1, ax=ax[0,0], alpha=0.4)\n",
    "        ax[0,0].set_ylabel('( True - Prediction ) / True')\n",
    "        ax[0,0].set_title('MODEL 1 - lr - Test data')      \n",
    "\n",
    "        ratio_pred2=(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "                         -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred2'])\\\n",
    "                            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']              \n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=ratio_pred2, ax=ax[0,1], alpha=0.4)     \n",
    "        ax[0,1].set_ylabel('( True - Prediction ) / True')\n",
    "        #ax[0,1].set_xlim(left=, right=)\n",
    "        ax[0,1].set_ylim(bottom=-1, top=1)\n",
    "        ax[0,1].set_title('MODEL 2 - Ridge - Test data')  \n",
    "        \n",
    "        ratio_pred31=(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "                          -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred31'])\\\n",
    "                            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=ratio_pred31, ax=ax[1,0], alpha=0.4)       \n",
    "        ax[1,0].set_ylabel('( True - Prediction ) / True')\n",
    "        ax[1,0].set_title('MODEL 3.1 - kNN - Test data')   \n",
    "\n",
    "        ratio_pred32=(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "                          -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred32'])\\\n",
    "                            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=ratio_pred32, ax=ax[1,1], alpha=0.4)       \n",
    "        ax[1,1].set_ylabel('( True - Prediction ) / True')\n",
    "        ax[1,1].set_title('MODEL 3.2 - RF - Test data')\n",
    "\n",
    "        ratio_pred33=(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "                          -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred33'])\\\n",
    "                            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "        sns.scatterplot(x=10**df_clean_scrome_test[c],\n",
    "                        y=ratio_pred33, ax=ax[1,2], alpha=0.4)     \n",
    "        ax[1,2].set_ylabel('( True - Prediction ) / True')\n",
    "        ax[1,2].set_title('MODEL 3.3 - SVR - Test data')    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting_trigger==1:\n",
    "    \n",
    "    check_scat_only_assy_ratio(['cout_unitaire_pour_la_qte_demandee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the same plotting on our alternative test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scat_only_assy_o(cols):\n",
    "    \n",
    "    for c in cols:        \n",
    "        sns.scatterplot(x=10**df_clean_other_test[c],\n",
    "                        y=df_clean_other_test['cout_unitaire_pour_la_qte_demandee_pred2'],\n",
    "                        alpha=0.4)      \n",
    "        plt.title('MODEL 2 - Ridge - OTHER Test data')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scat_only_assy_ratio_o(cols):\n",
    "    \n",
    "    for c in cols:\n",
    "        ratio_pred2=(10**df_clean_other_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "                         -df_clean_other_test['cout_unitaire_pour_la_qte_demandee_pred2'])\\\n",
    "                            /10**df_clean_other_test['cout_unitaire_pour_la_qte_demandee']              \n",
    "        sns.scatterplot(x=10**df_clean_other_test[c], y=ratio_pred2, alpha=0.4)     \n",
    "        plt.ylabel('( True - Prediction ) / True')\n",
    "        plt.title('MODEL 2 - Ridge - OTHER Test data')  \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting_trigger==1:\n",
    "        check_scat_only_assy_o(['cout_unitaire_pour_la_qte_demandee'])\n",
    "        check_scat_only_assy_ratio_o(['cout_unitaire_pour_la_qte_demandee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our relative erros are generally still high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to understand the origin of errors better.\n",
    "To do this we will analyse the points with most and least important mean absolute errors and see their position on the various features distribution.\n",
    "We do this on the test set, it would also be interesting to analyse the train set in this respect.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add columns corresponding to the MAE calculated on each datapoint\n",
    "# rapported to the data value\n",
    "\n",
    "df_clean_scrome_test['error_pred1']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred1'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_scrome_test['error_pred2']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred2'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_scrome_test['error_pred31']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred31'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_scrome_test['error_pred32']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred32'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_scrome_test['error_pred33']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred33'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_other_test['error_pred1']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred1'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_other_test['error_pred2']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred2'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_other_test['error_pred31']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred31'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_other_test['error_pred32']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred32'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\n",
    "\n",
    "df_clean_other_test['error_pred33']\\\n",
    "            =np.abs(10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']\\\n",
    "            -df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred33'])\\\n",
    "            /10**df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We identify the top and lowest errors, which we want to analyse further\n",
    "\n",
    "df_clean_scrome_test_head=\\\n",
    "                    df_clean_scrome_test.sort_values('error_pred2',\n",
    "                                                     ascending=False).head(20)\n",
    "\n",
    "df_clean_scrome_test_tail=\\\n",
    "                    df_clean_scrome_test.sort_values('error_pred2',\n",
    "                                                     ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display project with top errors\n",
    "\n",
    "df_clean_scrome_test_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display project with lowest errors\n",
    "\n",
    "df_clean_scrome_test_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the projects corresponding to head\n",
    "\n",
    "print('HEAD')\n",
    "display(df_merged[df_merged.index.isin(df_clean_scrome_test_head.index)]['calc_file'])\n",
    "\n",
    "# Display project drawing and informations\n",
    "for project_id in list(df_clean_scrome_test_head.index):\n",
    "    print('Project {}:'.format(project_id))\n",
    "    project_id_pdf_path=os.path.normpath(df_merged[df_merged.index==project_id]['pdf_file'].item())\n",
    "    if project_id_pdf_path[-2]=='d': \n",
    "        project_id_img_path=project_id_pdf_path[:-4]+'_page1from*_pre.jpg'\n",
    "    else:\n",
    "        project_id_img_path=project_id_pdf_path[:-5]+'_page1from*_pre.jpg'\n",
    "    #print('{}'.format(project_id_img_path))\n",
    "    jn=glob.glob(os.path.normpath(project_id_img_path))[0]\n",
    "    print(jn)\n",
    "    im=Image.open(jn)\n",
    "    size=800,800\n",
    "    im.thumbnail(size, Image.ANTIALIAS)\n",
    "    display(im)\n",
    "    display(pd.DataFrame(X_te[list(X_te_index).index(project_id),:], index=df_clean_scrome_cols).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the projects corresponding to tail\n",
    "\n",
    "print('TAIL')\n",
    "display(df_merged[df_merged.index.isin(df_clean_scrome_test_tail.index)]['calc_file'])\n",
    "\n",
    "# Display project drawing and informations\n",
    "for project_id in list(df_clean_scrome_test_tail.index):\n",
    "    print('Project {}:'.format(project_id))\n",
    "    project_id_pdf_path=os.path.normpath(df_merged[df_merged.index==project_id]['pdf_file'].item())\n",
    "    if project_id_pdf_path[-2]=='d': \n",
    "        project_id_img_path=project_id_pdf_path[:-4]+'_page1from*.jpg'\n",
    "    else:\n",
    "        project_id_img_path=project_id_pdf_path[:-5]+'_page1from*.jpg'\n",
    "    #print('{}'.format(project_id_img_path))\n",
    "    jn=glob.glob(os.path.normpath(project_id_img_path))[0]\n",
    "    print(jn)\n",
    "    im=Image.open(jn)\n",
    "    size=800,800\n",
    "    im.thumbnail(size, Image.ANTIALIAS)\n",
    "    display(im)\n",
    "    display(pd.DataFrame(X_te[list(X_te_index).index(project_id),:], index=df_clean_scrome_cols).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataframe for EDA on errors\n",
    "\n",
    "df_clean_scrome_test['error_pred2_headtail']='core'\n",
    "\n",
    "df_clean_scrome_test.loc[df_clean_scrome_test_tail.index,\n",
    "                         'error_pred2_headtail']='tail'\n",
    "\n",
    "df_clean_scrome_test.loc[df_clean_scrome_test_head.index,\n",
    "                         'error_pred2_headtail']='head'\n",
    "\n",
    "df_clean_scrome_test_topfeat=\\\n",
    "        df_clean_scrome_test[feature_names+['error_pred2_headtail']]\\\n",
    "        .astype(float, errors='ignore').copy()\n",
    "\n",
    "df_clean_scrome_test_allfeat=\\\n",
    "        df_clean_scrome_test\\\n",
    "        .astype(float, errors='ignore').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting position of head and tail of errors group on feature distribution\n",
    "\n",
    "if plotting_trigger == 1:\n",
    "    \n",
    "    for c in df_clean_scrome_test_topfeat.columns:#df_clean_scrome_cols\n",
    "        \n",
    "        x=df_clean_scrome_test_allfeat[c]\n",
    "        \n",
    "        sns.displot(x=x,kind='hist',\n",
    "                    hue=df_clean_scrome_test_allfeat['error_pred2_headtail'],\n",
    "                    multiple='stack',\n",
    "                    bins=20,\n",
    "                    hue_order=['core','head','tail'],\n",
    "                    palette=['white','r','g'])\n",
    "        \n",
    "        plt.title('Position errors head & tail on feature distribution')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From those plots we do not see clear situations where the models fail or succeed in predicting the target.  \n",
    "The head and tail elements seem to be spread in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare for plotting of additional insights: the location of the predicted points on the test set per feature in comparison to the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scat_assy(cols):\n",
    "    \n",
    "    for c in cols:\n",
    "        if df_clean_scrome_train[c].dtype==np.number:\n",
    "            fig, ax = plt.subplots(3,4, figsize=(16,12))\n",
    "\n",
    "            sns.distplot(df_clean_scrome_train[c],\n",
    "                         ax=ax[0,0],\n",
    "                         bins=50,\n",
    "                         fit=None,\n",
    "                         color='grey',\n",
    "                         norm_hist=True,\n",
    "                         hist=False,\n",
    "                         label='Train data - Original')\n",
    "            sns.distplot(df_clean_scrome_test[c],\n",
    "                         ax=ax[0,0],\n",
    "                         bins=50,\n",
    "                         fit=None,\n",
    "                         color='g',\n",
    "                         norm_hist=True,\n",
    "                         hist=False,\n",
    "                         label='Test data - Original')\n",
    "            ax[0,0].set_title('{}'.format(c))\n",
    "            ax[0,0].legend()\n",
    "\n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred33'],\n",
    "                        color='m',\n",
    "                        ax=ax[0,1],\n",
    "                        label='Train data - Prediction model 33',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)               \n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred32'],\n",
    "                        color='y',\n",
    "                        ax=ax[0,1],\n",
    "                        label='Train data - Prediction model 32',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)               \n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred31'],\n",
    "                        color='b',\n",
    "                        ax=ax[0,1],\n",
    "                        label='Train data - Prediction model 31',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)               \n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred2'],\n",
    "                        color='r',\n",
    "                        ax=ax[0,1],\n",
    "                        label='Train data - Prediction model 2',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)\n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred1'],\n",
    "                        color='g',\n",
    "                        ax=ax[0,1],\n",
    "                        label='Train data - Prediction model 1',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)\n",
    "            ax[0,1].set_title('TRAIN {}'.format(c))  \n",
    "            ax[0,1].legend()\n",
    "\n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred33'],\n",
    "                        color='m',\n",
    "                        ax=ax[0,2],\n",
    "                        label='Test data - Prediction model 33',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)\n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred32'],\n",
    "                        color='y',\n",
    "                        ax=ax[0,2],\n",
    "                        label='Test data - Prediction model 32',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)\n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred31'],\n",
    "                        color='b',\n",
    "                        ax=ax[0,2],\n",
    "                        label='Test data - Prediction model 31',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)               \n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred2'],\n",
    "                        color='r',\n",
    "                        ax=ax[0,2],\n",
    "                        label='Test data - Prediction model 2',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)\n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred1'],\n",
    "                        color='g',\n",
    "                        ax=ax[0,2],\n",
    "                        label='Test data - Prediction model 1',\n",
    "                        fill=False,\n",
    "                        alpha=0.4)\n",
    "            ax[0,2].set_title('TEST {}'.format(c))  \n",
    "            ax[0,2].legend()        \n",
    "\n",
    "\n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred2'],\n",
    "                        color='grey', ax=ax[1,0], label='Train data - Prediction model 2',\n",
    "                        shade=True,\n",
    "                        alpha=0.4)               \n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred2'],\n",
    "                        color='r',\n",
    "                        ax=ax[1,0],\n",
    "                        label='Test data - Prediction model 2',\n",
    "                        shade=True,\n",
    "                        alpha=0.4)        \n",
    "            ax[1,0].set_title('{}'.format(c))  \n",
    "            ax[1,0].legend()\n",
    "\n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred31'],\n",
    "                        color='grey',\n",
    "                        ax=ax[1,1],\n",
    "                        label='Train data - Prediction model 31',\n",
    "                        shade=True,\n",
    "                        alpha=0.4)               \n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred31'],\n",
    "                        color='b',\n",
    "                        ax=ax[1,1],\n",
    "                        label='Test data - Prediction model 31',\n",
    "                        shade=True,\n",
    "                        alpha=0.4)        \n",
    "            ax[1,1].set_title('{}'.format(c))  \n",
    "            ax[1,1].legend()\n",
    "\n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred32'],\n",
    "                        color='grey',\n",
    "                        ax=ax[1,2],\n",
    "                        label='Train data - Prediction model 32',\n",
    "                        shade=True,\n",
    "                        alpha=0.4)               \n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred32'],\n",
    "                        color='y',\n",
    "                        ax=ax[1,2],\n",
    "                        label='Test data - Prediction model 32',\n",
    "                        shade=True,\n",
    "                        alpha=0.4)        \n",
    "            ax[1,2].set_title('{}'.format(c))  \n",
    "            ax[1,2].legend()\n",
    "            \n",
    "            sns.kdeplot(x=df_clean_scrome_train[c],\n",
    "                        y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred33'],\n",
    "                        color='grey',\n",
    "                        ax=ax[1,3],\n",
    "                        label='Train data - Prediction model 33',\n",
    "                        shade=True,\n",
    "                        alpha=0.4)               \n",
    "            sns.kdeplot(x=df_clean_scrome_test[c],\n",
    "                        y=df_clean_scrome_test['cout_unitaire_pour_la_qte_demandee_pred33'],\n",
    "                        color='m',\n",
    "                        ax=ax[1,3],\n",
    "                        label='Test data - Prediction model 33',\n",
    "                        shade=True,\n",
    "                        alpha=0.4)        \n",
    "            ax[1,3].set_title('{}'.format(c))  \n",
    "            ax[1,3].legend()\n",
    "\n",
    "            sns.scatterplot(x=df_clean_scrome_train[c],\n",
    "                            y=10**df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee'],\n",
    "                            color='grey',\n",
    "                            ax=ax[2,0],\n",
    "                            label='Train data - Original',\n",
    "                            alpha=0.2)#,shade=True,                \n",
    "            sns.scatterplot(x=df_clean_scrome_train[c],\n",
    "                            y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred2'],\n",
    "                            color='r',\n",
    "                            ax=ax[2,0],\n",
    "                            label='Train data - Prediction model 2',\n",
    "                            alpha=0.2)#,shade=True        \n",
    "            ax[2,0].set_title('{}'.format(c))  \n",
    "            ax[2,0].legend()\n",
    "\n",
    "            sns.scatterplot(x=df_clean_scrome_train[c],\n",
    "                            y=10**df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee'],\n",
    "                            color='grey',\n",
    "                            ax=ax[2,1],\n",
    "                            label='Train data - Original',\n",
    "                            alpha=0.2)#,shade=True,                \n",
    "            sns.scatterplot(x=df_clean_scrome_train[c],\n",
    "                            y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred31'],\n",
    "                            color='b', \n",
    "                            ax=ax[2,1],\n",
    "                            label='Train data - Prediction model 31',\n",
    "                            alpha=0.2)#,shade=True        \n",
    "            ax[2,1].set_title('{}'.format(c))  \n",
    "            ax[2,1].legend()      \n",
    "\n",
    "            sns.scatterplot(x=df_clean_scrome_train[c],\n",
    "                            y=10**df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee'],\n",
    "                            color='grey',\n",
    "                            ax=ax[2,2],\n",
    "                            label='Train data - Original',\n",
    "                            alpha=0.2)#,shade=True,                \n",
    "            sns.scatterplot(x=df_clean_scrome_train[c],\n",
    "                            y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred32'],\n",
    "                            color='y',\n",
    "                            ax=ax[2,2],\n",
    "                            label='Train data - Prediction model 32',\n",
    "                            alpha=0.2)#,shade=True        \n",
    "            ax[2,2].set_title('{}'.format(c))  \n",
    "            ax[2,2].legend()\n",
    "\n",
    "            sns.scatterplot(x=df_clean_scrome_train[c],\n",
    "                            y=10**df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee'],\n",
    "                            color='grey',\n",
    "                            ax=ax[2,3],\n",
    "                            label='Train data - Original',\n",
    "                            alpha=0.2)#,shade=True,                \n",
    "            sns.scatterplot(x=df_clean_scrome_train[c],\n",
    "                            y=df_clean_scrome_train['cout_unitaire_pour_la_qte_demandee_pred33'],\n",
    "                            color='m',\n",
    "                            ax=ax[2,3],\n",
    "                            label='Train data - Prediction model 33',\n",
    "                            alpha=0.2)#,shade=True        \n",
    "            ax[2,3].set_title('{}'.format(c))  \n",
    "            ax[2,3].legend()\n",
    "\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "if plotting_trigger==2:\n",
    "\n",
    "    print(quant_features)    \n",
    "    #bool_features\n",
    "    #cat_features\n",
    "    \n",
    "    for c in quant_features:\n",
    "        check_scat_assy([c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Predictions - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this setup we can reach and average MAE of around 20Eur, depending on the conditions, and we obtain predictions on the test sets in a ±50% range when we would need a value in the range of ±5%, an acceptable error in relation to a typical project margin.\n",
    "\n",
    "We now have a system in place to perform analysis on our datapoint and try to increase the score of our models. We have the following ideas for continuation:  \n",
    "\n",
    "We see a possibility to increase the quality of our prediction on the target discussed by incorporating more information in our features, mainly more symbols and the step source. For the more symbols we need a detector, for the steps files, we need to wait the our parnter generates the data.  \n",
    "\n",
    "We also see as an additional topic of investigation the different levels of score for the different targets, such as internal costs, or machining cost alone, instead of taking as target the total project costs. Perhaps we could see that the model does not predict well some portion of the cost - say the external ones - but can predict correctly some other portion of the costs - say the internal ones.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
